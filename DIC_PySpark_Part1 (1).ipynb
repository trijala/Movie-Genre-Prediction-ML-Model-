{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wEYVVO555Lli"
   },
   "outputs": [],
   "source": [
    "# !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "# !wget -q https://archive.apache.org/dist/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz\n",
    "# !tar xf spark-2.4.0-bin-hadoop2.7.tgz\n",
    "# !pip install -q findspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "8YRSZ6kK3Qer",
    "outputId": "cfe3b3f9-fbf9-42bb-b773-af55b532fe20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIC_PySpark_Part1.ipynb Untitled3.ipynb         \u001b[34mspark-warehouse\u001b[m\u001b[m\r\n",
      "Untitled.ipynb          Untitled4.ipynb         test.csv\r\n",
      "Untitled1.ipynb         mapping.csv             train.csv\r\n",
      "Untitled2.ipynb         sample.csv\r\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "# os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.0-bin-hadoop2.7\"\n",
    "# !pip install -q findspark\n",
    "\n",
    "import findspark\n",
    "findspark.init('/Users/vamshi/Documents/spark-3.0.0-preview2-bin-hadoop2.7')\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "# spark = SparkSession.builder.master(\"local[*]\")\\\n",
    "#         .config(\"spark.executor.memory\", \"16g\")\\\n",
    "#         .config(\"spark.driver.memory\", \"16g\")\\\n",
    "#         .config(\"spark.memory.offHeap.enabled\",'true')\\\n",
    "#         .config(\"spark.memory.offHeap.size\",\"16g\")\\\n",
    "#         .getOrCreate()\n",
    "\n",
    "\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HoHi4QdC5apa"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval \n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType, IntegerType, ArrayType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.sql.functions import regexp_replace,col,array_contains,explode\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import concat_ws\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "76Y4Nnuc6OK5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_df = pd.read_csv(r'train.csv')\n",
    "data_spark_df = spark.createDataFrame(pd_df)\n",
    "pd_df['genre']= pd_df['genre'].apply(literal_eval)\n",
    "all_genre = pd_df['genre'].to_list()\n",
    "# names =['Drama','Comedy','Romance Film','Thriller','Action','World cinema','Crime Fiction','Horror','Black-and-white','Indie','Action/Adventure','Adventure','Family Film','Short Film','Romantic drama','Animation','Musical','Science Fiction','Mystery','Romantic comedy']\n",
    "\n",
    "df_mapping = pd.read_csv(\"mapping.csv\")\n",
    "dfspark_mapping = spark.createDataFrame(df_mapping)\n",
    "\n",
    "genres = []\n",
    "for i in range(dfspark_mapping.count()):\n",
    "    genres.append(dfspark_mapping.take(20)[i][1])\n",
    "\n",
    "matrix = np.zeros((len(pd_df),len(genres)))\n",
    "for i,genre in enumerate(all_genre):\n",
    "  for j,g in enumerate(genre):\n",
    "    for k,name in enumerate(genres):\n",
    "        if name==g:\n",
    "          matrix[i][k] = 1\n",
    "names = \"Drama , Comedy , Romance Film , Thriller , Action , World cinema , Crime Fiction , Horror , Black-and-white , Indie , Action/Adventure , Adventure , Family Film , Short Film , Romantic drama , Animation , Musical , Science Fiction , Mystery , Romantic comedy\"\n",
    "np.savetxt(\"genre_lables.csv\", matrix, delimiter=\",\",fmt='%d',header=names)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4wMajSknMC3W"
   },
   "outputs": [],
   "source": [
    "lables_df = pd.read_csv(r'genre_lables.csv')\n",
    "test_pd_df = pd.read_csv(r'test.csv')\n",
    "lables_spark_df = spark.createDataFrame(lables_df)\n",
    "test_spark_df = spark.createDataFrame(test_pd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lZUNn84K21fS"
   },
   "outputs": [],
   "source": [
    "ddf1 = data_spark_df.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "ddf2 = lables_spark_df.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "ddf3 = test_spark_df.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "df = ddf1.join(ddf2, \"row_id\").drop(\"row_id\")\n",
    "test_df = ddf3.join(ddf2, \"row_id\").drop(\"row_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Z593o_L88AEK",
    "outputId": "6a3870e3-a024-4aef-cee9-190937b2be33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 69.7 ms, sys: 14.9 ms, total: 84.6 ms\n",
      "Wall time: 814 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"plot\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"features\")\n",
    "pipeline = Pipeline(stages=[regexTokenizer, remover, hashingTF])\n",
    "\n",
    "model = pipeline.fit(df)\n",
    "dataset = model.transform(df)\n",
    "\n",
    "model2 = pipeline.fit(test_df)\n",
    "test_dataset = model2.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W0ZqhfSMApxm"
   },
   "outputs": [],
   "source": [
    "# train_dataset, validation_dataset = dataset.randomSplit([1.0, 0.0], seed = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bI_skgB9HaAT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.13 s, sys: 822 ms, total: 2.95 s\n",
      "Wall time: 7min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfList = []\n",
    "labelCols = lables_spark_df.columns\n",
    "lr = LogisticRegression(featuresCol = 'features',maxIter=1)\n",
    "# lr = LogisticRegression(featuresCol = 'features',maxIter=50)\n",
    "for labelCol in labelCols:\n",
    "    lr.setLabelCol(labelCol)\n",
    "    # lrModel = lr.fit(train_dataset)\n",
    "    lrModel = lr.fit(dataset)\n",
    "    predictions = lrModel.transform(test_dataset)\n",
    "    # predictions = predictions.drop(\"features\",labelCol,\"rawPrediction\",\"probability\")\n",
    "    predictions = predictions.withColumn(\"prediction\",F.col(\"prediction\").cast(IntegerType()))\n",
    "    dfList.append(predictions.select(\"movie_id\",\"prediction\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6m2q85P2sqBl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 932 ms, sys: 447 ms, total: 1.38 s\n",
      "Wall time: 8min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfs_renamed = [df.selectExpr('movie_id', f'prediction as prediction_{i}') for i, df in enumerate(dfList)]\n",
    "temp_df = reduce(lambda x, y: x.join(y, ['movie_id'], how='full'), dfs_renamed)\n",
    "col_list = ['prediction_%d' % i for i in range(len(dfList))]\n",
    "temp_df = temp_df.withColumn('predictions',concat_ws(\" \",*col_list)).drop(*col_list).toPandas().to_csv(\"predictions_part1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for i in range(dfspark_mapping.count()):\n",
    "    names.append(dfspark_mapping.take(20)[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Drama',\n",
       " 'Comedy',\n",
       " 'Romance Film',\n",
       " 'Thriller',\n",
       " 'Action',\n",
       " 'World cinema',\n",
       " 'Crime Fiction',\n",
       " 'Horror',\n",
       " 'Black-and-white',\n",
       " 'Indie',\n",
       " 'Action/Adventure',\n",
       " 'Adventure',\n",
       " 'Family Film',\n",
       " 'Short Film',\n",
       " 'Romantic drama',\n",
       " 'Animation',\n",
       " 'Musical',\n",
       " 'Science Fiction',\n",
       " 'Mystery',\n",
       " 'Romantic comedy']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DIC_PySpark_Part1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
